---
title: 'Descriptive Statistics'
teaching: 10
exercises: 2
editor_options: 
  markdown: 
    wrap: 72
---

::: questions
-   How can we describe a set of data?
:::

::: objectives
-   Learn about the most common ways of describing a variable
:::

## Introduction

::: instructor
Det kan være en udfordring hvis deltagene ikke ved hvad et gennemsnit
er.

En af de overordnede pointer vi gerne vil frem til her, er percentilerne og 
det kumulative densitetsplot - der danner grundlag for forståelsen af 
normalfordelingens sammenhæng med statistiske tests.
:::

Descriptive statistic involves summarising or describing a set of data.
It usually presents quantitative descriptions in a short form, and helps
to simplify large datasaets.

Most descriptive statistical parameters applies to just one variable in
our data, and includes:

| Central tendency | Measure of variation | Measure of shape |
|------------------|----------------------|------------------|
| Mean             | Range                | Skewness         |
| Median           | Quartiles            | Kurtosis         |
| mode             | Inter Quartile Range |                  |
|                  | Variance             |                  |
|                  | Standard deviation   |                  |
|                  | Percentiles          |                  |

# Central tendency

The easiest way to get summary statistics on data is to use the
`summarise` function from the `tidyverse` package.

```{r message=FALSE}
library(tidyverse)
```

In the following we are working with the `palmerpenguins` dataset. Note that
the actual data is called `penguins` and is part of the package `palmerpenguins`:

```{r}
library(palmerpenguins)
head(penguins)
```
344 penguins have been recorded at three different islands over three years. 
Three different penguin species are in the dataset, and we have data on their 
weight, sex, length of their flippers and two measurements of their bill (beak).

![What is lenght and depth of penguin bills?](../episodes/fig/culmen_depth.png){Copyright Allison Horst}


Specifically we are going to work with the weight of the penguins, stored in the variable
`body_mass_g`:

```{r}
penguins$body_mass_g
```

How can we describe these values?

## Mean

The mean is the average of all datapoints. We add all values (excluding
the missing values encoded with `NA`), and divide with the number of
observations:

$$\overline{x} = \frac{1}{N}\sum_1^N x_i$$ Where N is the number of
observations, and $x_i$ is the individual observations in the sample
$x$.

The easiest way of getting the mean is using the `mean()` function:

```{r}
mean(penguins$body_mass_g, na.rm = TRUE)
```

A slightly more cumbersome way is using the summarise function from
`tidyverse`:

```{r}
penguins %>% 
  summarise(avg_mass = mean(body_mass_g, na.rm = T))
```

The advantage will be clear below.

Barring significant outliers, `mean` is an expression of position of the
data. This is the weight we would expect a random penguin in our dataset
to have.

However, we have three different species of penguins in the
dataset, and they have quite different average weights. There is also a
significant difference in the average weight for the two sexes. 

We will get to that at the end of this segment.

## Median

Similarly to the average/mean, the `median` is an expression of the
location of the data. If we order our data by size, from the smallest to
the largest value, and locate the middle observation, we get the median.
This is the value that half of the observations is smaller than. And
half the observations is larger.

```{r}
penguins %>% 
  summarise(median = median(body_mass_g, na.rm = T))
```

We can note that the mean is larger that the median. This indicates that
the data is skewed, in this case toward the larger penguins.

We can get both `median` and `mean` in one go:

```{r}
penguins %>% 
  summarise(median = median(body_mass_g, na.rm = T),
            mean   = mean(body_mass_g, na.rm = TRUE))
```

::: instructor
This illustrates for the learners that we can calculate more than one
summary statistics in one summarise function.
:::

## Mode

Mode is the most common, or frequently occurring, observation. R does
not have a build-in function for this, but we can easily find the mode
by counting the different observations,and locating the most common one.

We typically do not use this for continous variables. The mode of the
`sex` variable in this dataset can be found like this:

```{r}
penguins %>% 
  count(sex) %>% 
  arrange(desc(n))
```

We count the different values in the `sex` variable, and arrange the
counts in descending order (`desc`). The mode of the `sex` variable is
male.

In this specific case, we note that the dataset is pretty evenly balanced
regarding the two sexes.




# Measures of variance

Knowing where the observations are located is interesting. But how do
they vary? How can we describe the variation in the data?

## Range

The simplest information about the variation is the range. What is the
smallest and what is the largest value? Or, what is the spread?

We can get that by using the `min()` and `max()` functions in a `summarise()` 
function:

```{r}
penguins %>% 
  summarise(min = min(body_mass_g, na.rm = T),
            max = max(body_mass_g, na.rm = T))
```

There is a dedicated function, `range()`, that does the same.
However it returns two values (for each row), and the summarise function
expects to get _one_ value. 

If we would like to use the `range()` function, we can add it using the 
`reframe()` function instead of `summarise()`: 

```{r}
penguins %>% 
  reframe(range = range(body_mass_g, na.rm = T))
```

:::: instructor

Hvorfor ikke bare bruge reframe generelt? Kognitivt load. Summarise angiver
hvad det er vi gør. Vi summariser noget data. Reframe angiver hvordan vi 
omdanner et output til en dataframe. Resultatet bliver det samme, men 
vi taler ikke længere om hvad det egentlig er vi er ude efter i operationen.

::::

## Variance

The observations varies. They are no all located at the mean (or
median), but are spread out on both sides of the mean. Can we get a
numerical value describing that?

An obvious way would be to calculate the difference between each of the
observations and the mean, and then take the average of those
differences.

That will give us the average deviation. But we have a problem. The
average weight of penguins was 4202 (rounded). Look at two penguins, one
weighing 5000, and another weighing 3425. The differences are:

-   5000 - 4202 = 798
-   3425 - 4202 = -777

The sum of those two differences is: -777 + 798 = 21 g. And the average
is then 10.5 gram. That is *not* a good estimate of a variation from the
mean of more than 700 gram.

The problem is, that the differences can be both positive and negative,
and might cancel each other out.

We solve that problem by squaring the differences, and calculate the
mean of those.

::: instructor
Why not just averaging the absolute values? Using the square rather than
the absolute difference, weighs the deviations so larger deviations have
relatively larger influence on the variance. Squaring results in a
continous and differentiable function, which helps in situations where
we have to do an optimisation. Also the normal distribution is defined
by the variance as defined here, and we would really like to get a
connection between what we observe here, and the normal distribution.
:::

The mathematical notation would be:

$$
\sigma^2 = \frac{\sum_{i=1}^N(x_i - \mu)^2}{N}
$$

Why are we suddenly using $\mu$ instead of $\overline{x}$? Because this
definition uses the population mean. The mean, or average, in the entire
population of all penguins everywhere in the universe. But we have not
weighed all those penguins. 

Instead we will normally look at the sample variance:

$$
s^2 = \frac{\sum_{i=1}^N(x_i - \overline{x})^2}{N-1}
$$

Note that we also change the $\sigma$ to an $s$.

And again we are not going to do that by hand, but will ask R to do it
for us:

```{r}
penguins %>% 
  summarise(
            variance = var(body_mass_g, na.rm = T)
          )
```

::::: instructor

Et godt spørgsmål vil være - hvorfor dividerer vi med N-1 i stedet for N?

Det kaldes for en "Bessel korrektion". Den ene årsag til at vi gør det er, 
at godt nok er gennemsnittet i stikprøven et godt estimat for gennemsnittet i 
populationen. Men det er ikke præcis det samme. Når vi dividerer med et mindre tal,
får vi en større værdi for variancen - og dermed et mere konservativt, eller forsigtigt,
estimat på variansen. 

Den anden årsag handler om frihedsgrader. Hvis vi har tre værdier og et gennemsnit,
kan vi vælge hvad de to af værdierne er, og hvad gennemsnittet er. Helt frit. Men
den tredie værdi er givet. Den kan vi ikke vælge frit. 
:::::

## Standard deviation

There is a problem with the variance. It is 643131, completely off scale
from the actual values. There is also a problem with the unit which is in
$g^2$.

A measurement of the variation of the data would be the standard
deviation, simply defined as the square root of the variance:

```{r}
penguins %>% 
  summarise(
            s = sd(body_mass_g, na.rm = T)
          )
```

Since the standard deviation occurs in several statistical tests, it is
more frequently used than the variance. It is also more intuitively
relateable to the mean.

## A histogram
A visual illustration of the data can be nice. Often one of the first we make, is
a histogram. 

A histogram is a plot or graph where we split the range of observations
in a number of "buckets", and count the number of observations in each
bucket:

```{r}
penguins %>% 
  select(body_mass_g) %>% 
  filter(!is.na(body_mass_g)) %>% 
  mutate(buckets = cut(body_mass_g, breaks=seq(2500,6500,500))) %>% 
group_by(buckets) %>% 
summarise(antal = n())
```

Typically, rather than counting ourself, we leave the work to R, and
make a histogram directly:

```{r}
penguins %>% 
ggplot((aes(x=body_mass_g))) +
geom_histogram()
```

By default ggplot chooses 30 bins, typically we should chose a different
number:

```{r}
penguins %>% 
ggplot((aes(x=body_mass_g))) +
geom_histogram(bins = 25)
```

Or, ideally, set the widths of them, manually:

```{r}
penguins %>% 
ggplot((aes(x=body_mass_g))) +
geom_histogram(binwidth = 250) +
ggtitle("Histogram with binwidth = 250 g")
```
Or even specify the exact intervals we want, here intervals from 0 to 6500 gram
in intervals of 250 gram:

```{r}
penguins %>% 
ggplot((aes(x=body_mass_g))) +
geom_histogram(breaks = seq(0,6500,250)) +
ggtitle("Histogram with bins in 250 g steps from 0 to 6500 g")
```
The histogram provides us with a visual indication of both range, the variation
of the values, and an idea about where the data is located.

## Quartiles

The median can be understood as splitting the data in two equally sized
parts, where one is characterized by having values smaller than the
median and the other as having values larger than the median. It is the
value where 50% of the observations are smaller.

Similary we can calculate the value where 25% of the observations are
smaller.

That is often called the first quartile, where the median is the 50%, or
second quartile. Quartile implies four parts, and the existence of a
third or 75% quartile.

We can calcultate those using the quantile function:

```{r}
quantile(penguins$body_mass_g, probs = .25, na.rm = T)
```

and

```{r}
quantile(penguins$body_mass_g, probs = .75, na.rm = T)
```

::: instructor
probs because if we select a random penguin, we have a 25% chance of
selecting a penguin that weighs less than 3550 gram. This ties in to
percentiles and qq-plots.
:::

We are often interested in knowing the range in which 50% of the
observations fall.

That is used often enough that we have a dedicated function for it:

```{r}
penguins %>% 
  summarise(iqr = IQR(body_mass_g, na.rm = T))
```

The name of the quantile function implies that we might have other
quantiles than quartiles. Actually we can calculate any quantile, eg the
2.5% quantile:

```{r}
quantile(penguins$body_mass_g, probs = .025, na.rm = T)
```

The individual quantiles can be interesting in themselves. If we want a
visual representation of *all* quantiles, we can calculate all of them,
and plot them.

Instead of doing that by hand, we can use a concept called *CDF* or
cumulative density function:

```{r}
CDF <- ecdf(penguins$body_mass_g)
CDF
```

That was not very informative. Lets plot it:

[NOT QUITE DONE!]

```{r warning=FALSE}
quantiler <- quantile(penguins$body_mass_g, probs = c(0.25, 0.75), na.rm = TRUE)
ggplot(penguins, aes(body_mass_g)) + 
  stat_ecdf(geom = "step") +
  geom_hline(yintercept = c(0.25,0.5,0.75)) +
geom_vline(xintercept = quantiler)
```
den skal vi nok have beskrevet lidt mere.

Men pointen er, at vi for enhver værdi kan aflæse ting. Hvor stor en andel
af pingvinerne vejer mindre end 3000 g? Vi kan finde 3000 på x-aksen, og aflæse
den matchende værdi på y-aksen. 

Det svarer også til - hvis vi tager en tilfældig pingvin, hvad er så sandsynligheden
for at den vejer mindre end 3000 gram? Eller for at den vejer mere end 5000 gram?

## Measures of shape

## Skewness
Vi bliver nok nødt til at lave et histogram...

We previously saw a histogram of the data, and noted that the
observations were skewed to the left, and that the "tail" on the right
was longer than on the left. That skewness can be quantised.

There is no function for skewness build into R, but we can get it from
the library `e1071`

```{r}
library(e1071)
skewness(penguins$body_mass_g, na.rm = T)
```

The skewness is positive, indicating that the data are skewed to the
left, just as we saw. A negative skewness would indicate that the data
skew to the right.

## Kurtosis

Og her skal vi nok lige have styr på den intuitive forståelse af det.

## Everything Everywhere All at Once

A lot of these descriptive values can be gotten for every variable in
the dataset using the `summary` function:

```{r}
summary(penguins)
```

Here we get the range, the 1st and 3rd quantiles (and from those the
IQR), the median and the mean and, rather useful, the number of missing
values in each variable.

We can also get all the descriptive values in one table, by adding more
than one summarizing function to the summarise function:

```{r}
penguins %>% 
  summarise(min = min(body_mass_g, na.rm = T),
            max = max(body_mass_g, na.rm = T),
            mean = mean(body_mass_g, na.rm = T),
            median = median(body_mass_g, na.rm = T),
            stddev = sd(body_mass_g, na.rm = T),
            var = var(body_mass_g, na.rm = T),
            Q1 = quantile(body_mass_g, probs = .25, na.rm = T),
            Q3 = quantile(body_mass_g, probs = .75, na.rm = T),
            iqr = IQR(body_mass_g, na.rm = T),
            skew = skewness(body_mass_g, na.rm = T),
            kurtosis = kurtosis(body_mass_g, na.rm = T)
  )
```



As noted, we have three different species of penguins in the dataset.
Their weight varies a lot. If we want to do the summarising on each for
the species, we can group the data by species, before summarising:

```{r}
penguins %>% 
  group_by(species) %>% 
  summarise(min = min(body_mass_g, na.rm = T),
            max = max(body_mass_g, na.rm = T),
            mean = mean(body_mass_g, na.rm = T),
            median = median(body_mass_g, na.rm = T),
            stddev = sd(body_mass_g, na.rm = T)
  )
```

We have removed some summary statistics in order to get a smaller table.

## Boxplots

Finally boxplots offers a way of visualising some of the summary
statistics:

```{r}
penguins %>% 
  ggplot(aes(x=body_mass_g, y = sex)) +
  geom_boxplot()
```

The boxplot shows us the median (the fat line in the middel of each
box), the 1st and 3rd quartiles (the ends of the boxes), and the range,
with the whiskers at each end of the boxes, illustrating the minimum and
maximum. Any observations, more than 1.5 times the IQR from either the
1st or 3rd quartiles, are deemed as outliers and would be plotted as
individual points in the plot.


::: keypoints
-   Nogen statisktiske pointer om det her
:::
